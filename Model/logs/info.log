2021-05-17 23:35:22,025 [INFO]: MultiInstanceLearning(
  (bert): Bert(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(28996, 768)
      (position_embeddings): Embedding(512, 768)
      (token_type_embedding): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): Encoder(
      (layer): ModuleList(
        (0): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): EncoderLayer(
          (self_attention): MultiHeadAttentionLayer(
            (fc_q): Linear(in_features=768, out_features=768, bias=True)
            (fc_k): Linear(in_features=768, out_features=768, bias=True)
            (fc_v): Linear(in_features=768, out_features=768, bias=True)
            (fc_o): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (self_attention_dropout): Dropout(p=0.1, inplace=False)
          (self_attention_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (positionwise_feedforward): PositionwiseFeedforwardLayer(
            (fc_1): Linear(in_features=768, out_features=3072, bias=True)
            (fc_2): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (positionwise_feedforward_dropout): Dropout(p=0.1, inplace=False)
          (positionwise_feedforward_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (pooler): Pooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
    )
  )
  (dense_layer): Linear(in_features=768, out_features=100, bias=True)
  (pcnn): PCNN(
    (pos1_embedding): Embedding(256, 5, padding_idx=0)
    (pos2_embedding): Embedding(256, 5, padding_idx=0)
    (dropout): Dropout(p=0.1, inplace=False)
    (conv): Conv1d(110, 230, kernel_size=(3,), stride=(1,), padding=(1,))
    (pool): MaxPool1d(kernel_size=128, stride=128, padding=0, dilation=1, ceil_mode=False)
    (mask_embedding): Embedding(4, 3)
  )
  (fc): Linear(in_features=690, out_features=5, bias=True)
  (softmax): Softmax(dim=-1)
  (dropout): Dropout(p=0.1, inplace=False)
)
Trainable parameters: 82145
